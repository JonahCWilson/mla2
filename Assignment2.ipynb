{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import mlrose_hiive as mlrose\n",
    "from mlrose_hiive import NeuralNetwork, simulated_annealing, random_hill_climb, NNClassifier, genetic_alg\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "    \n",
    "def load_occupancy_training():\n",
    "    enc = OrdinalEncoder()\n",
    "    \n",
    "    f = open('./datatraining.txt')\n",
    "    lines = f.readlines()[1:] #eliminate categories\n",
    "    lines = [line.strip().split(',') for line in lines]\n",
    "    f.close()\n",
    "    \n",
    "    X, y = [ls[:-1] for ls in lines],[ls[-1] for ls in lines]\n",
    "    enc.fit(X)\n",
    "    X = enc.transform(X)\n",
    "    y = [int(i) for i in y]\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def load_occupancy_test():\n",
    "    enc = OrdinalEncoder()\n",
    "    \n",
    "    f = open('./datatest.txt')\n",
    "    lines = f.readlines()[1:] #eliminate categories\n",
    "    lines = [line.strip().split(',') for line in lines]\n",
    "    f.close()\n",
    "    \n",
    "    X, y = [ls[:-1] for ls in lines],[ls[-1] for ls in lines]\n",
    "    enc.fit(X)\n",
    "    X = enc.transform(X)\n",
    "    y = [int(i) for i in y]\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def get_best_model(scores):\n",
    "    best = 0\n",
    "    best_index = 0\n",
    "    s = scores['test_score']\n",
    "    for i in range(len(s)):\n",
    "        if s[i] > best:\n",
    "            best = s[i]\n",
    "            best_index = i\n",
    "\n",
    "    best_model = scores['estimator'][best_index]\n",
    "    return best_model\n",
    "\n",
    "def get_best_score(scores):\n",
    "    best = 0\n",
    "    best_index = 0\n",
    "    s = scores['test_score']\n",
    "    for i in range(len(s)):\n",
    "        if s[i] > best:\n",
    "            best = s[i]\n",
    "            best_index = i\n",
    "        \n",
    "    return best, best_index\n",
    "\n",
    "# Load and separate Occupancy Training, Validation, and Test Sets\n",
    "\n",
    "occupancyTrainX, occupancyTrainY = load_occupancy_training()\n",
    "occTestX, occTestY = load_occupancy_test()\n",
    "\n",
    "occTrainX, occValidX, occTrainY, occValidY = train_test_split(occupancyTrainX, occupancyTrainY, test_size=.2)\n",
    "\n",
    "# Load ad separate Digit Training, Validation, and Test Sets\n",
    "\n",
    "digitData, digitTarget = load_digits(return_X_y=True)\n",
    "trainDigitX, testDigitX, trainDigitY, testDigitY = train_test_split(digitData, digitTarget, test_size=.2)\n",
    "\n",
    "trainDigitX, validDigitX, trainDigitY, validDigitY = train_test_split(trainDigitX, trainDigitY, test_size=.2, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve plotting function\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
      "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(2, 2), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "0.6361111111111111\n",
      "0.6354166666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Neural Networks\n",
    "\n",
    "# nn = MLPClassifier()\n",
    "# nn.fit(trainDigitX, trainDigitY)\n",
    "# print(nn)\n",
    "# plot_learning_curve(nn, \"Neural Network Training\", trainDigitX, trainDigitY)\n",
    "\n",
    "# Create Parameter Dict for GridSearch\n",
    "\n",
    "params = {\n",
    "    'activation': 'logistic',\n",
    "    'max_iter': 2500,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "grid_params = {\n",
    "    'activation': ['identity'],\n",
    "    'max_iter': [500],\n",
    "    'random_state': [0],\n",
    "    'solver': ['sgd'],\n",
    "    'hidden_layer_sizes': [(2,2)]\n",
    "}\n",
    "\n",
    "nn = MLPClassifier()\n",
    "clf = GridSearchCV(nn, param_grid=grid_params, n_jobs=3)\n",
    "clf.fit(trainDigitX, trainDigitY)\n",
    "best = clf.best_estimator_\n",
    "print(best)\n",
    "plot_learning_curve(best, \"Test\", trainDigitX, trainDigitY, n_jobs=3)\n",
    "\n",
    "ypred = best.predict(testDigitX)\n",
    "print(accuracy_score(ypred, testDigitY))\n",
    "ypred = best.predict(validDigitX)\n",
    "print(accuracy_score(ypred, validDigitY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6622889305816135\n",
      "0.6352720450281426\n",
      "0.6525328330206379\n"
     ]
    }
   ],
   "source": [
    "# Neural Network - Random Hill Climbing\n",
    "\n",
    "# Format Data For mlrose\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(occTrainX)\n",
    "X_test_scaled = scaler.transform(occTestX)\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(occTrainY.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(occTestY.reshape(-1, 1)).todense()\n",
    "\n",
    "# nn_model1 = mlrose.NeuralNetwork(hidden_nodes = [2], activation ='relu', \n",
    "#                                  algorithm ='random_hill_climb', \n",
    "#                                  max_iters = 1000, bias = True, is_classifier = True, \n",
    "#                                  learning_rate = 0.0001, early_stopping = True, \n",
    "#                                  clip_max = 5, max_attempts = 100, random_state = 3)\n",
    "\n",
    "params = {\n",
    "    'hidden_nodes': [2,2],\n",
    "    'activation': 'identity',\n",
    "    'algorithm': 'random_hill_climb',\n",
    "    'max_iters': 500,\n",
    "    'random_state': 0\n",
    "}\n",
    "nn = NeuralNetwork(**params)\n",
    "nn.fit(X_train_scaled, y_train_hot)\n",
    "\n",
    "\n",
    "ypred = nn.predict(X_test_scaled)\n",
    "print(accuracy_score(ypred, y_test_hot))\n",
    "\n",
    "params['algorithm'] = 'simulated_annealing'\n",
    "nn = NeuralNetwork(**params)\n",
    "nn.fit(X_train_scaled, y_train_hot)\n",
    "\n",
    "ypred = nn.predict(X_test_scaled)\n",
    "print(accuracy_score(ypred, y_test_hot))\n",
    "\n",
    "params['algorithm'] = 'genetic_alg'\n",
    "nn = NeuralNetwork(**params)\n",
    "nn.fit(X_train_scaled, y_train_hot)\n",
    "\n",
    "ypred = nn.predict(X_test_scaled)\n",
    "print(accuracy_score(ypred, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_half_and_end(state):\n",
    "    # Maximize number of ones in first half of state, and have a 1 at the very end\n",
    "    mid = len(state)//2\n",
    "    left = state[:mid]\n",
    "    right = state[mid:-1]\n",
    "    \n",
    "    \n",
    "    return sum(left) + state[-1] + (len(right) - sum(right))\n",
    "\n",
    "def max_three_zeros(state):\n",
    "    #Attempts to maximize the number of 000 in the given list.\n",
    "    i = 0\n",
    "    zeros_count = 0\n",
    "    total = 0\n",
    "    while i <= len(state):\n",
    "        if i == len(state):\n",
    "            total = total + 1 if zeros_count == 3 else total\n",
    "            break\n",
    "        if state[i] == 0:\n",
    "            zeros_count += 1\n",
    "        elif zeros_count == 3:\n",
    "            total += 1\n",
    "            zeros_count = 0\n",
    "        else:\n",
    "            zeros_count = 0\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    return total\n",
    "\n",
    "\n",
    "# print(max_half_and_end([1,1,1,1,1,0,0,0,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "32.0\n",
      "(10, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "# Randomized Hill Climbing using OneMax\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 32\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "restarts = [0, 10, 50, 100, 250]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters, restarts)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = mlrose.OneMax(), maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'init_state': init_state,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    param_grid['restarts'] = combo[2]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose.random_hill_climb(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "32.0\n",
      "(10, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "# Randomized Hill Climbing using max_half_and_end\n",
    "\n",
    "fitness = mlrose.CustomFitness(max_half_and_end)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 32\n",
    "attempts = [10, 50, 100]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "restarts = [0, 10, 50]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters, restarts)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'init_state': init_state,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    param_grid['restarts'] = combo[2]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose_hiive.random_hill_climb(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      "8.0\n",
      "(10, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "# Randomized Hill Climbing using max_three_zeros\n",
    "\n",
    "fitness = mlrose.CustomFitness(max_three_zeros)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 32\n",
    "attempts = [10, 50, 100]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "restarts = [0, 10, 50]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters, restarts)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'init_state': init_state,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    param_grid['restarts'] = combo[2]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose.random_hill_climb(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "32.0\n",
      "(ExpDecay(init_temp=1.0, exp_const=0.005, min_temp=0.001), 50, 500)\n"
     ]
    }
   ],
   "source": [
    "# Simulated Annealing using OneMax\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 32\n",
    "schedules = [mlrose.ExpDecay(), mlrose.GeomDecay(), mlrose.ArithDecay()]\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(schedules, attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = mlrose.OneMax(), maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'init_state': init_state,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['schedule'] = combo[0]\n",
    "    param_grid['max_attempts'] = combo[1]\n",
    "    param_grid['max_iters'] = combo[2]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose.simulated_annealing(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "32.0\n",
      "(ExpDecay(init_temp=1.0, exp_const=0.005, min_temp=0.001), 100, 500)\n"
     ]
    }
   ],
   "source": [
    "# Simulated Annealing using max_half_and_end\n",
    "\n",
    "fitness = mlrose.CustomFitness(max_half_and_end)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 32\n",
    "schedules = [mlrose.ExpDecay(), mlrose.GeomDecay(), mlrose.ArithDecay()]\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(schedules, attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'init_state': init_state,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['schedule'] = combo[0]\n",
    "    param_grid['max_attempts'] = combo[1]\n",
    "    param_grid['max_iters'] = combo[2]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose_hiive.simulated_annealing(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      "8.0\n",
      "(GeomDecay(init_temp=1.0, decay=0.99, min_temp=0.001), 500, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Simulated Annealing using max_three_zeros\n",
    "\n",
    "fitness = mlrose.CustomFitness(max_three_zeros)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 32\n",
    "schedules = [mlrose.ExpDecay(), mlrose.GeomDecay(), mlrose.ArithDecay()]\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(schedules, attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'init_state': init_state,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['schedule'] = combo[0]\n",
    "    param_grid['max_attempts'] = combo[1]\n",
    "    param_grid['max_iters'] = combo[2]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose_hiive.simulated_annealing(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "100.0\n",
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "# Genetic Algorithm using OneMax\n",
    "\n",
    "# genetic_alg(problem, pop_size=200, mutation_prob=0.1, max_attempts=10, max_iters=inf, curve=False, random_state=None)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 100\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = mlrose.OneMax(), maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose_hiive.genetic_alg(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "100.0\n",
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "# Genetic Algorithm using max_half_and_end\n",
    "\n",
    "# genetic_alg(problem, pop_size=200, mutation_prob=0.1, max_attempts=10, max_iters=inf, curve=False, random_state=None)\n",
    "\n",
    "fitness = mlrose_hiive.CustomFitness(max_half_and_end)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 100\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose_hiive.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose_hiive.genetic_alg(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0]\n",
      "23.0\n",
      "(10, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Genetic Algorithm using max_three_zeros\n",
    "\n",
    "# genetic_alg(problem, pop_size=200, mutation_prob=0.1, max_attempts=10, max_iters=inf, curve=False, random_state=None)\n",
    "\n",
    "fitness = mlrose_hiive.CustomFitness(max_three_zeros)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 100\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose_hiive.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose_hiive.genetic_alg(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "32.0\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "# MIMIC - OneMax\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 32\n",
    "attempts = [10, 50]\n",
    "iters = [10, 50, 100]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = mlrose.OneMax(), maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose.mimic(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC - max_half_and_end\n",
    "\n",
    "fitness = mlrose.CustomFitness(max_half_and_end)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 100\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose.mimic(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC - max_three_zeros\n",
    "\n",
    "fitness = mlrose.CustomFitness(max_three_zeros)\n",
    "\n",
    "#Define function constants\n",
    "LENGTH = 100\n",
    "attempts = [10, 50, 100, 500, 1000]\n",
    "iters = [10, 50, 100, 500, 1000]\n",
    "init_state = np.array([0 for i in range(LENGTH)])\n",
    "\n",
    "combos = itertools.product(attempts, iters)\n",
    "\n",
    "\n",
    "# Define optimization problem object\n",
    "problem = mlrose.DiscreteOpt(length = LENGTH, fitness_fn = fitness, maximize=True, max_val=2)\n",
    "\n",
    "param_grid = {\n",
    "    'problem': problem,\n",
    "    'random_state': 0\n",
    "}\n",
    "\n",
    "current_state = current_fitness = 0\n",
    "best_state = best_fitness = 0\n",
    "best_combo = None\n",
    "\n",
    "for combo in combos:\n",
    "    param_grid['max_attempts'] = combo[0]\n",
    "    param_grid['max_iters'] = combo[1]\n",
    "    \n",
    "    current_state, current_fitness, _ = mlrose.mimic(**param_grid)\n",
    "    if current_fitness > best_fitness:\n",
    "        best_fitness = current_fitness\n",
    "        best_state = current_state\n",
    "        best_combo = combo\n",
    "\n",
    "\n",
    "print(best_state)\n",
    "print(best_fitness)\n",
    "print(best_combo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
